{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction of the paper [Visualizing and understanding RNNs](https://arxiv.org/abs/1506.02078)\n",
    "Project for the subject [344.063 Special Topics Natural Language Processing with Deep Learning ](https://kusss.jku.at/kusss/sz-lvadetail-overview.action?courseId=344063%2C2020S)\n",
    "\n",
    "Authors: M. Vogl, F. Shalaby\n",
    "\n",
    "Limitation: We only worked with 3mb warandpeace.txt, as the linux kernel dataset grew from 400mb during the writing of the paper to 800mb, which wouldn't fit into my GPU as a one-hot-able LongTensor.\n",
    "\n",
    "Training for the 3x4x6 grid (with early stopping and parameters seen in config.txt) for 3mb warandpeace.txt took ~4h on a GTX2070Super.\n",
    "\n",
    "**Improvements to other implementations**\n",
    "* Using pytorch and lightning instead of lua-torch unlike the [original kapathy charrnn](https://github.com/karpathy/char-rnn)\n",
    "* Still working with a current pytorch version unlike the great [huango implementation](https://github.com/huanghao-code/VisRNN_ICLR_2016_Text) \n",
    "* Shoter code - easier to understand: Old implementation. 1500+ LOC. New: 400 LOC (Counted with <br>`projects find proj -name \"*.py\" -print -exec cat {} \\; | wc -l`)\n",
    "* This version is extending the torch builtin [LSTM](https://pytorch.org/docs/master/generated/torch.nn.LSTM.html)/[GRU](https://pytorch.org/docs/master/generated/torch.nn.GRU.html)/[RNN](https://pytorch.org/docs/master/generated/torch.nn.RNN.html) with activation gate extraction, which is 10-100x faster than the other implementations. Includes support for apex 16 bit precision, cuda and optimized dataloading.\n",
    "\n",
    "This file assumes you have downloaded the models (too big for github) from [http://öä.eu/models.zip](http://öä.eu/models.zip).\n",
    "\n",
    "Hyperparameters from config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "\n",
      "# linux = https://cs.stanford.edu/people/karpathy/char-rnn/\n",
      "_FILE_NAMES = [\"shakespeare\"] #, \"warandpeace\"]\n",
      "FILE_NAME = _FILE_NAMES[0]\n",
      "FILE_PATH = f\"data/{FILE_NAME}.txt\"\n",
      "MODEL_PATH = \"models/\" #\"/content/gdrive/MyDrive/DL-project/\" #\n",
      "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
      "N_LAYERS = 2\n",
      "SEQ_LEN = 70\n",
      "HIDDEN_SIZE = 32\n",
      "BATCH_SIZE = 128\n",
      "PREDICT_SEQ_LEN = SEQ_LEN\n",
      "LR = 0.01\n",
      "CLIP = 5\n",
      "DROPOUT = 0.0\n",
      "MAX_EPOCHS = 100\n",
      "EMBEDDING_DIM = 0  # 0 = one-hot encoding\n",
      "MODEL_NAME = \"lstm\"\n",
      "PRECISION = 32  # 16 if DEVICE == \"cuda\" else 32\n",
      "SPLITS = (0, 90, 95, 100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(open(\"config.py\").read())  # hyperparameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, IFrame\n",
    "# from matplotlib_venn import venn3\n",
    "\n",
    "import dataloader\n",
    "from config import *\n",
    "from visualize import visualize_gate, visualize_cell\n",
    "from net.charrnn import CharRNN\n",
    "%matplotlib inline\n",
    "\n",
    "(trl, tel, val), vocab = dataloader.load(FILE_PATH, DEVICE, SPLITS, BATCH_SIZE, SEQ_LEN, unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand\tHello 3RRGTF?QiXT$HRZKuKXKJSXJ$$3pNQKP\n",
      "MP.OKzBAHQ$BGW..Fa!uABNI.XaQKY!.WV\n",
      ":XB$Fxi;F?TKJK&:u\n",
      "kX?yZF[KL!RfVR;jZEAV?XSGAcUP-xTJZ$vLB$C;v$YKPM[x-:G;R&A$DRiF?HDS$jK]Rs$NX3x!PjP,MyzBPMsQ:POLa;RyIWsAQ3!NQDFJX]Aww&\n",
      "max\tHello the son of the common son,\n",
      "That the son of the common son of the son,\n",
      "And the son of the son of the son of the son,\n",
      "And the son of the son of the son of the son,\n",
      "And the son of the son of the son of t\n",
      "softrand\tHello be\n",
      "Than sure it to these and most humouraratant have a many,\n",
      "Whilst repute it when every sport safets.'\n",
      "\n",
      "CLIFFORD:\n",
      "Os\n",
      "A perfection moved power to your a's hell in rebel bemp that shame;\n",
      "For we have ve\n"
     ]
    }
   ],
   "source": [
    "net = CharRNN.load_from_file(\"lstm\", 3, 256).eval()\n",
    "for method in \"rand\", \"max\", \"softrand\":\n",
    "    print(method, net.predict(\"Hello \", 200, vocab, method=method), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance table - Training | Test - Loss | Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">lstm</th>\n",
       "      <th colspan=\"3\" halign=\"left\">rnn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">gru</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.577</td>\n",
       "      <td>1.450</td>\n",
       "      <td>1.337</td>\n",
       "      <td>1.202</td>\n",
       "      <td>1.490</td>\n",
       "      <td>1.339</td>\n",
       "      <td>1.313</td>\n",
       "      <td>1.496</td>\n",
       "      <td>1.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.387</td>\n",
       "      <td>1.411</td>\n",
       "      <td>1.308</td>\n",
       "      <td>1.746</td>\n",
       "      <td>1.596</td>\n",
       "      <td>1.601</td>\n",
       "      <td>2.450</td>\n",
       "      <td>1.651</td>\n",
       "      <td>1.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>3.308</td>\n",
       "      <td>3.339</td>\n",
       "      <td>1.646</td>\n",
       "      <td>2.154</td>\n",
       "      <td>3.322</td>\n",
       "      <td>3.337</td>\n",
       "      <td>1.604</td>\n",
       "      <td>1.451</td>\n",
       "      <td>1.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1.445</td>\n",
       "      <td>1.497</td>\n",
       "      <td>1.385</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1.703</td>\n",
       "      <td>1.526</td>\n",
       "      <td>1.402</td>\n",
       "      <td>1.460</td>\n",
       "      <td>1.453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lstm                  rnn                  gru              \n",
       "         1      2      3      1      2      3      1      2      3\n",
       "64   1.577  1.450  1.337  1.202  1.490  1.339  1.313  1.496  1.485\n",
       "128  1.387  1.411  1.308  1.746  1.596  1.601  2.450  1.651  1.563\n",
       "256  3.308  3.339  1.646  2.154  3.322  3.337  1.604  1.451  1.393\n",
       "512  1.445  1.497  1.385  1.405  1.703  1.526  1.402  1.460  1.453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'test data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">lstm</th>\n",
       "      <th colspan=\"3\" halign=\"left\">rnn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">gru</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.659</td>\n",
       "      <td>1.542</td>\n",
       "      <td>1.448</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.586</td>\n",
       "      <td>1.453</td>\n",
       "      <td>1.433</td>\n",
       "      <td>1.581</td>\n",
       "      <td>1.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.485</td>\n",
       "      <td>1.521</td>\n",
       "      <td>1.442</td>\n",
       "      <td>1.808</td>\n",
       "      <td>1.670</td>\n",
       "      <td>1.669</td>\n",
       "      <td>2.459</td>\n",
       "      <td>1.723</td>\n",
       "      <td>1.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>3.305</td>\n",
       "      <td>3.334</td>\n",
       "      <td>1.717</td>\n",
       "      <td>2.175</td>\n",
       "      <td>3.320</td>\n",
       "      <td>3.335</td>\n",
       "      <td>1.675</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1.538</td>\n",
       "      <td>1.571</td>\n",
       "      <td>1.482</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.769</td>\n",
       "      <td>1.609</td>\n",
       "      <td>1.491</td>\n",
       "      <td>1.548</td>\n",
       "      <td>1.541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lstm                  rnn                  gru              \n",
       "         1      2      3      1      2      3      1      2      3\n",
       "64   1.659  1.542  1.448  1.378  1.586  1.453  1.433  1.581  1.584\n",
       "128  1.485  1.521  1.442  1.808  1.670  1.669  2.459  1.723  1.642\n",
       "256  3.305  3.334  1.717  2.175  3.320  3.335  1.675  1.539  1.478\n",
       "512  1.538  1.571  1.482  1.500  1.769  1.609  1.491  1.548  1.541"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_names = [\"lstm\", \"rnn\", \"gru\"]\n",
    "n_layers = [1, 2, 3]\n",
    "hidden_sizes = [64, 128, 256, 512]\n",
    "\n",
    "for loader, loadername in (trl, \"train data\"), (tel, \"test data\"):\n",
    "    corrects, losses = [], []\n",
    "    display(loadername)\n",
    "    for MODEL_NAME in model_names:\n",
    "        for N_LAYERS in n_layers:\n",
    "            for HIDDEN_SIZE in hidden_sizes:\n",
    "                net = CharRNN.load_from_file(MODEL_NAME, N_LAYERS, HIDDEN_SIZE).eval()\n",
    "                loss = [] #correct, loss = [], []\n",
    "                for x, y in loader:\n",
    "                    out = net.forward(x)\n",
    "#                     correct += (out.argmax(-1) == y.flatten()).tolist()\n",
    "                    loss += [(torch.nn.functional.cross_entropy(out, y.flatten())).tolist()]\n",
    "#                 corrects.append(np.mean(correct))\n",
    "                losses.append(np.mean(loss))\n",
    "\n",
    "#     for title, arr in ((\"accuracy\", corrects), (\"loss\", losses)):\n",
    "    title, arr = \"loss\", losses\n",
    "    arr = np.array(arr).reshape((len(hidden_sizes), len(model_names) * len(n_layers)))\n",
    "    columns = pd.MultiIndex.from_product([model_names, n_layers])\n",
    "    df = pd.DataFrame(arr, columns=columns, index=hidden_sizes)\n",
    "    df.columns.name = title\n",
    "    display(df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gate Visualization (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net = CharRNN.load_from_file(\"lstm\", 3, 512).eval()\n",
    "input_gates, forget_gates, cell_gates, output_gates, cell_states = net.extract_from_loader(tel)\n",
    "visualize_gate(input_gates, forget_gates, output_gates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell visualization (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 225400, 512)\n"
     ]
    }
   ],
   "source": [
    "net = CharRNN.load_from_file(\"lstm\", 2, 512).eval()\n",
    "reset_gates = net.extract_from_loader(tel)[3,:,:,:]\n",
    "print(reset_gates.shape)\n",
    "visualize_cell(reset_gates[:, 50:1000], dataloader.decode(tel.dataset.data[50:1000], vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase of the rnn cell visualization\n",
    "![screenshot](visualization/screenshot.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
